{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9687e7ca-ebe2-4efa-8281-f55c52858c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LassoCV, LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19910e76-62ec-4f20-a732-8eed11eaeb5d",
   "metadata": {},
   "source": [
    "# 1.æ•°æ®å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9492d9eb-392a-42a4-a99d-97701b04760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"D:\\è®ºæ–‡æ•°æ®\\2025.2 å‡ºå£é€‰æ‹©\\20190519+é—®å·ç»Ÿè®¡è¡¨.csv\", encoding='utf-8') \n",
    "data = data.drop('åºå·', axis=1)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f58f5ca-f5fc-4e1a-9a96-8ff73406156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    'æ€§åˆ«': 'Gen',\n",
    "    'å¹´é¾„æ®µ': 'Age',\n",
    "    'æ•™è‚²ç¨‹åº¦': 'Edu',\n",
    "    'è¡ŒåŠ¨èƒ½åŠ›': 'Mob',\n",
    "    'æ‚¨ä¹˜åå®¢èˆ¹çš„ç»å†ï¼ˆä¸å«æœ¬æ¬¡ï¼‰': 'PCE',\n",
    "    'ä¸æ‚¨ä¸€èµ·å‡ºè¡Œçš„äººå‘˜æ•°é‡': 'GS',\n",
    "    'æ¥å—èˆ¹èˆ¶ç–æ•£æ•™è‚²/è®­ç»ƒçš„ç»å†': 'ET',                     \n",
    "    'å¬åˆ°ç–æ•£é€ƒç”Ÿè­¦æŠ¥ï¼Œæ‚¨ä¼šç­‰å¾…å·¥ä½œäººå‘˜ç¡®è®¤åå†è¡ŒåŠ¨': 'WFS',\n",
    "    'å¬åˆ°ç–æ•£é€ƒç”Ÿè­¦æŠ¥ï¼Œæ‚¨ä¼šç«‹å³ç–æ•£é€ƒç”Ÿ': 'EI',\n",
    "    'å¬åˆ°ç–æ•£é€ƒç”Ÿè­¦æŠ¥ï¼Œæ‚¨ä¼šè§‚å¯Ÿå…¶ä»–äººçš„åŠ¨é™å†è¡ŒåŠ¨': 'OO',\n",
    "    'å‡å¦‚å¬åˆ°ç–æ•£é€ƒç”Ÿè­¦æŠ¥ï¼Œæ‚¨ä¼šè‡ªè¡Œå¼€é—¨æŸ¥çœ‹ç¡®è®¤': 'PC',      \n",
    "    'ç–æ•£é€ƒç”Ÿæ—¶ï¼Œæ‚¨ä¼šé€‰æ‹©è·ç¦»æœ€è¿‘çš„å‡ºå£': 'NE',  #\n",
    "    'ç–æ•£é€ƒç”Ÿæ—¶ï¼Œæ‚¨ä¼šé€‰æ‹©æœ€ç†Ÿæ‚‰çš„å‡ºå£': 'FE',  #\n",
    "    'ç–æ•£é€ƒç”Ÿæ—¶ï¼Œæ‚¨ä¼šé€‰æ‹©è·Ÿç€å¤§å¤šæ•°äººèµ°': 'FM',  #\n",
    "    'ç–æ•£é€ƒç”Ÿæ—¶ï¼Œæ‚¨ä¼šé€‰æ‹©å¬ä»ç–æ•£æŒ‡ç¤ºæˆ–å¹¿æ’­': 'FI',  #       \n",
    "    'æ‚¨ä¼šè€å¿ƒæ’é˜Ÿç­‰å¾…': 'QP',\n",
    "    'æ‚¨ä¼šè‡ªè¡Œå¯»æ‰¾å…¶ä»–å‡ºå£': 'SOE',  \n",
    "    'æ‚¨ä¼šå¾€å‰æŒ¤è¡Œ': 'SF',\n",
    "    'æ‚¨ä¼šå¬ä»èˆ¹å‘˜å¼•å¯¼': 'OC',\n",
    "    'è´µé‡ç‰©å“é—ç•™ï¼Œæ‚¨æ˜¯å¦ä¼šè¿”å›å¯»æ‰¾': 'RIV',\n",
    "    'å®¶äººé—ç•™ï¼Œæ‚¨æ˜¯å¦ä¼šè¿”å›å¯»æ‰¾': 'RIF',\n",
    "    'ç–æ•£è¿‡ç¨‹ä¸­ï¼Œæ‚¨æ˜¯å¦ä¼šååŠ©ä»–äººè¿›è¡Œç–æ•£': 'HO',\n",
    "    'ç–æ•£è¿‡ç¨‹ä¸­ï¼Œæ‚¨æ˜¯å¦ä¼šè¶…è¶Šä»–äººæˆ–å‘å‰æŒ¤è¡Œ': 'OtO',\n",
    "    'ç–æ•£é€ƒç”Ÿæ—¶ï¼Œæ‚¨æ˜¯å¦ä¼šå¯»æ‰¾åŒä¼´ä¸€èµ·é€ƒç”Ÿ': 'FC',\n",
    "    'å‡å¦‚å‘ç”Ÿç«ç¾ï¼Œæ‚¨æ˜¯å¦ä¼šå‡ºç°ææ…Œå¿ƒç†': 'EP',\n",
    "    'ç–æ•£æ—¶ï¼Œæ‚¨æ˜¯å¦ä¼šæºå¸¦å¤§ä»¶è¡Œæç®±': 'CL',\n",
    "    'ç–æ•£æ—¶ï¼Œæ‚¨æ˜¯å¦ä¼šè·Ÿä»å›¢é˜Ÿä¸­çš„ä¸´æ—¶é¢†å¯¼è€…': 'FL'\n",
    "}\n",
    "data.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc69c3bd-6476-40ad-b233-c2bf91a9ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data\n",
    "df_ec = df.drop(columns=['NE', 'FE', 'FM', 'FI'])\n",
    "df_ne = df.drop(columns=['FE', 'FM', 'FI'])\n",
    "df_fe = df.drop(columns=['NE', 'FM', 'FI'])\n",
    "df_fm = df.drop(columns=['NE', 'FE', 'FI'])\n",
    "df_fi = df.drop(columns=['NE', 'FE', 'FM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a979c11-1c0c-4d54-9c71-96749b1b547e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gen', 'Age', 'Edu', 'Mob', 'PCE', 'GS', 'ET', 'WFS', 'EI', 'OO', 'PC',\n",
       "       'QP', 'SOE', 'SF', 'OC', 'RIV', 'RIF', 'HO', 'OtO', 'FC', 'EP', 'CL',\n",
       "       'FL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ec.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095624a9-d038-4983-b1eb-e4acfe982342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "398faf90-c325-42c4-8597-cd9208b55091",
   "metadata": {},
   "source": [
    "# 2.é›†æˆå› æœæ¨æ–­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "312190b2-b2a1-47df-bdec-a87599bf1e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# æ•°æ®é¢„å¤„ç†\n",
    "# =======================\n",
    "# å‰éƒ¨å˜é‡ï¼ˆè¡Œä¸ºä¸å¿ƒç†å› ç´ ï¼‰\n",
    "front_vars = ['Gen', 'Age', 'Edu', 'Mob', 'PCE', 'GS', 'ET', 'WFS', 'EI', 'OO', 'PC',\n",
    "       'QP', 'SOE', 'SF', 'OC', 'RIV', 'RIF', 'HO', 'OtO', 'FC', 'EP', 'CL',\n",
    "       'FL']\n",
    "\n",
    "# åéƒ¨å˜é‡ï¼ˆå‡ºå£é€‰æ‹©è¡Œä¸ºï¼‰\n",
    "exit_vars = ['NE', 'FE', 'FM', 'FI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "039ac3e7-dc9b-4a27-af04-f947c0af2a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           NE        FE        FM        FI   Mean_MI\n",
      "PC   0.260047  0.209781  0.161722  0.131412  0.190740\n",
      "QP   0.124216  0.127224  0.159045  0.292917  0.175851\n",
      "OO   0.209364  0.178317  0.135709  0.106433  0.157456\n",
      "WFS  0.181809  0.158733  0.141905  0.109891  0.148085\n",
      "EI   0.181910  0.172366  0.148715  0.085770  0.147190\n",
      "OC   0.117207  0.140884  0.078377  0.127573  0.116010\n",
      "SOE  0.089438  0.111212  0.112625  0.098241  0.102879\n",
      "SF   0.074033  0.097036  0.078704  0.081900  0.082918\n",
      "FC   0.051598  0.069714  0.049209  0.078044  0.062141\n",
      "OtO  0.068178  0.042249  0.044786  0.059655  0.053717\n",
      "EP   0.046869  0.020227  0.059665  0.069919  0.049170\n",
      "HO   0.075756  0.045221  0.037388  0.028617  0.046746\n",
      "RIF  0.054854  0.059158  0.046048  0.024434  0.046123\n",
      "RIV  0.041381  0.040443  0.031358  0.038559  0.037935\n",
      "CL   0.045507  0.045691  0.009095  0.031615  0.032977\n",
      "FL   0.034154  0.028437  0.028270  0.028614  0.029869\n",
      "Age  0.000000  0.036236  0.025906  0.055782  0.029481\n",
      "Mob  0.027178  0.000000  0.015035  0.047283  0.022374\n",
      "PCE  0.038733  0.027786  0.015812  0.000000  0.020583\n",
      "ET   0.055245  0.006644  0.000000  0.000000  0.015472\n",
      "GS   0.018198  0.010503  0.024396  0.000000  0.013275\n",
      "Gen  0.000000  0.007368  0.000000  0.027656  0.008756\n",
      "Edu  0.012612  0.010928  0.002122  0.000000  0.006415\n"
     ]
    }
   ],
   "source": [
    "# è®¡ç®—äº’ä¿¡æ¯\n",
    "mi_scores = {}\n",
    "for exit_var in exit_vars:\n",
    "    mi = mutual_info_classif(df[front_vars], df[exit_var], discrete_features='auto')\n",
    "    mi_scores[exit_var] = dict(zip(front_vars, mi))\n",
    "\n",
    "# è½¬æ¢ä¸ºDataFrame\n",
    "mi_df = pd.DataFrame(mi_scores)\n",
    "\n",
    "# è®¡ç®—æ¯ä¸ªå‰éƒ¨å˜é‡çš„å¹³å‡å½±å“åŠ›\n",
    "mi_df[\"Mean_MI\"] = mi_df.mean(axis=1)\n",
    "\n",
    "# æŒ‰å½±å“åŠ›æ’åº\n",
    "mi_df_sorted = mi_df.sort_values(by=\"Mean_MI\", ascending=False)\n",
    "\n",
    "print(mi_df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab8de2c1-0bdd-4bdb-b056-08281b6a7c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¤„ç†å˜é‡\n",
    "Control_vars = ['Gen','Edu','Mob','GS','ET','FL' ]\n",
    "\n",
    "# å¤„ç†å˜é‡\n",
    "Treatment_vars = ['Age', 'PCE', 'WFS', 'EI', 'OO', 'PC',\n",
    "       'QP', 'SOE', 'SF', 'OC', 'RIV', 'RIF', 'HO', 'OtO', 'FC', 'EP', 'CL']\n",
    "\n",
    "# ç»“æœå˜é‡ï¼ˆå‡ºå£é€‰æ‹©è¡Œä¸ºï¼‰\n",
    "Outcome_vars = ['NE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69191ae0-d6fb-4b27-adb9-cd56d079128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#å› æœæ£®æ— å› æœBoosting dml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1621581-bf61-4389-84f1-91acb8348ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_control = df[Control_vars]\n",
    "X_treat = df[Treatment_vars]\n",
    "Y_outcomes = df[Outcome_vars]\n",
    "\n",
    "# æ ‡å‡†åŒ–æ§åˆ¶å˜é‡\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_control), columns=Control_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de0277c-eeb5-4362-a749-07563cd2df13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e68a37-73f0-4556-a9db-2a209211dd34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2787cc48-3d32-4542-b650-bda4de005735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_causal_models(Y, T, X_scaled, random_state=42):\n",
    "    \"\"\"è¿è¡Œä¸‰ä¸ªå› æœæ¨¡å‹å¹¶è¿”å›ä¸ªä½“æ•ˆåº”ä¼°è®¡ï¼ˆç¨³å®šç‰ˆï¼‰\"\"\"\n",
    "\n",
    "    epsilon = 1e-3  # é˜²æ­¢åˆ†æ¯è¿‡å°\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    # ========================================\n",
    "    # 1ï¸âƒ£ æ¨¡å‹1ï¼šéšæœºæ£®æ—å› æœä¼°è®¡ï¼ˆCausal Forestè¿‘ä¼¼ï¼‰\n",
    "    # ========================================\n",
    "    rf = RandomForestRegressor(random_state=random_state)\n",
    "    rf_param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [5, 10, 20, None],\n",
    "        'min_samples_leaf': [2, 5, 10]\n",
    "    }\n",
    "    rf_search = RandomizedSearchCV(rf, rf_param_grid, n_iter=5, cv=3, n_jobs=-1, random_state=random_state)\n",
    "    rf_search.fit(X_scaled, Y)\n",
    "    best_rf = rf_search.best_estimator_\n",
    "\n",
    "    # è¾…åŠ©æ¨¡å‹é¢„æµ‹ T\n",
    "    rf_t = RandomForestRegressor(n_estimators=200, min_samples_leaf=10, random_state=random_state)\n",
    "    rf_t.fit(X_scaled, T)\n",
    "\n",
    "    y_resid = Y - best_rf.predict(X_scaled)\n",
    "    t_resid = T - rf_t.predict(X_scaled)\n",
    "\n",
    "    tau_cf = np.divide(y_resid, np.where(np.abs(t_resid)<epsilon, epsilon*np.sign(t_resid), t_resid))\n",
    "    tau_cf = np.nan_to_num(tau_cf, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # ========================================\n",
    "    # 2ï¸âƒ£ æ¨¡å‹2ï¼šCausal Boostingï¼ˆXGBoostæ®‹å·®æ³•ï¼‰\n",
    "    # ========================================\n",
    "    # æ‹ŸåˆYå’ŒT\n",
    "    xgb_y = xgb.XGBRegressor(n_estimators=500, max_depth=5, learning_rate=0.05,\n",
    "                             objective='reg:squarederror', random_state=random_state)\n",
    "    xgb_y.fit(X_scaled, Y)\n",
    "    y_pred = xgb_y.predict(X_scaled)\n",
    "    y_res = Y - y_pred\n",
    "\n",
    "    xgb_t = xgb.XGBRegressor(n_estimators=500, max_depth=5, learning_rate=0.05,\n",
    "                             objective='reg:squarederror', random_state=random_state)\n",
    "    xgb_t.fit(X_scaled, T)\n",
    "    t_pred = xgb_t.predict(X_scaled)\n",
    "    t_res = T - t_pred\n",
    "\n",
    "    tau_cb = np.divide(y_res, np.where(np.abs(t_res)<epsilon, epsilon*np.sign(t_res), t_res))\n",
    "    tau_cb = np.nan_to_num(tau_cb, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # ========================================\n",
    "    # 3ï¸âƒ£ æ¨¡å‹3ï¼šDMLè¿‘ä¼¼\n",
    "    # ========================================\n",
    "    # å¯ä»¥ä½¿ç”¨ä¸ tau_cb ç›¸åŒçš„æ®‹å·®æ–¹æ³•ï¼Œæˆ–è€…æ¢ KNN\n",
    "    knn_y = KNeighborsRegressor(n_neighbors=10)\n",
    "    knn_y.fit(X_scaled, Y)\n",
    "    y_pred_knn = knn_y.predict(X_scaled)\n",
    "    y_res_knn = Y - y_pred_knn\n",
    "\n",
    "    knn_t = KNeighborsRegressor(n_neighbors=10)\n",
    "    knn_t.fit(X_scaled, T)\n",
    "    t_pred_knn = knn_t.predict(X_scaled)\n",
    "    t_res_knn = T - t_pred_knn\n",
    "\n",
    "    tau_dml = np.divide(y_res_knn, np.where(np.abs(t_res_knn)<epsilon, epsilon*np.sign(t_res_knn), t_res_knn))\n",
    "    tau_dml = np.nan_to_num(tau_dml, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    return tau_cf, tau_cb, tau_dml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3ff2d4f-2622-458a-88aa-fa1849551c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Step 3. é›†æˆé€»è¾‘ï¼šè‡ªåŠ¨åŠ æƒèåˆï¼ˆåŸºäºRMSEï¼‰\n",
    "# -----------------------------\n",
    "def ensemble_effect(Y, tau_cf, tau_cb, tau_dml):\n",
    "    \"\"\"\n",
    "    æ ¹æ®è®­ç»ƒé›†ä¸Šçš„RMSEè‡ªåŠ¨è®¡ç®—æƒé‡å¹¶èåˆä¸‰ç§å› æœä¼°è®¡\n",
    "    Y: çœŸå®ç»“æœ\n",
    "    tau_cf, tau_cb, tau_dml: å„æ¨¡å‹å¯¹è®­ç»ƒé›†çš„ä¸ªä½“æ•ˆåº”é¢„æµ‹\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    # è®¡ç®—æ¯ä¸ªæ¨¡å‹çš„RMSE\n",
    "    rmse_cf = np.sqrt(mean_squared_error(Y, tau_cf))\n",
    "    rmse_cb = np.sqrt(mean_squared_error(Y, tau_cb))\n",
    "    rmse_dml = np.sqrt(mean_squared_error(Y, tau_dml))\n",
    "\n",
    "    # æ ¹æ®RMSEåæ¯”è®¾ç½®æƒé‡ï¼ˆRMSEè¶Šå°ï¼Œæƒé‡è¶Šå¤§ï¼‰\n",
    "    inv_rmse = np.array([1/rmse_cf, 1/rmse_cb, 1/rmse_dml])\n",
    "    weights = inv_rmse / np.sum(inv_rmse)  # å½’ä¸€åŒ–åˆ° [0,1]\n",
    "\n",
    "    # åŠ æƒèåˆ\n",
    "    tau_ens = weights[0]*tau_cf + weights[1]*tau_cb + weights[2]*tau_dml\n",
    "\n",
    "    # è¿”å›èåˆç»“æœå’Œæƒé‡\n",
    "    return tau_ens, weights[0], weights[1], weights[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20f8e468-d489-43d2-ba5f-4fbae9b4c862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¸ é›†æˆå› æœæ¨æ–­ç»“æœ: NE\n",
      "\n",
      "âœ… é›†æˆæ¨¡å‹ATEæ±‡æ€»ï¼š\n",
      "  Outcome Treatment    ATE_CF    ATE_CB   ATE_DML  ATE_Ensemble  Weight_CF  \\\n",
      "0      NE       Age -0.086412 -0.731176  0.116558     -0.036550   0.111443   \n",
      "1      NE       PCE -2.995044 -2.115121  0.271666     -0.181901   0.071678   \n",
      "2      NE       WFS -0.300264 -2.286899  0.236650      0.008757   0.219916   \n",
      "3      NE        EI  0.281518  0.340859  0.366814      0.336871   0.295015   \n",
      "4      NE        OO  0.644948 -0.755556  0.474902      0.300818   0.079490   \n",
      "\n",
      "   Weight_CB  Weight_DML  \n",
      "0   0.153925    0.734631  \n",
      "1   0.091929    0.836393  \n",
      "2   0.043517    0.736567  \n",
      "3   0.184155    0.520831  \n",
      "4   0.152464    0.768045  \n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 4. ä¸»å¾ªç¯ï¼šè®¡ç®—å„ç»“æœä¸å¤„ç†å˜é‡çš„ATE\n",
    "# ---------------------------------------------------------\n",
    "results = []  \n",
    "\n",
    "for outcome in Outcome_vars:\n",
    "    print(f\"\\nğŸ”¸ é›†æˆå› æœæ¨æ–­ç»“æœ: {outcome}\")\n",
    "    Y = df[outcome].values\n",
    "\n",
    "    for treat in Treatment_vars:\n",
    "        T = df[treat].values\n",
    "\n",
    "        # æ‹Ÿåˆä¸‰ä¸ªæ¨¡å‹\n",
    "        tau_cf, tau_cb, tau_dml = fit_causal_models(Y, T, X_scaled)\n",
    "\n",
    "        # åŠ æƒé›†æˆ\n",
    "        tau_ens, w_cf, w_cb, w_dml = ensemble_effect(Y, tau_cf, tau_cb, tau_dml)\n",
    "\n",
    "        # æ±‡æ€»ç»“æœ\n",
    "        results.append({\n",
    "            \"Outcome\": outcome,\n",
    "            \"Treatment\": treat,\n",
    "            \"ATE_CF\": np.mean(tau_cf),\n",
    "            \"ATE_CB\": np.mean(tau_cb),\n",
    "            \"ATE_DML\": np.mean(tau_dml),\n",
    "            \"ATE_Ensemble\": np.mean(tau_ens),\n",
    "            \"Weight_CF\": w_cf,\n",
    "            \"Weight_CB\": w_cb,\n",
    "            \"Weight_DML\": w_dml\n",
    "        })\n",
    "\n",
    "df_result = pd.DataFrame(results)\n",
    "print(\"\\nâœ… é›†æˆæ¨¡å‹ATEæ±‡æ€»ï¼š\")\n",
    "print(df_result.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7abb539d-478a-42cc-87ac-cc12e97168de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ç»“æœå·²ä¿å­˜è‡³ï¼šD:\\è®ºæ–‡æ•°æ®\\2025.10 å‡ºå£é€‰æ‹©\\ensemble_causal_results.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 5. ä¿å­˜ç»“æœ\n",
    "# ---------------------------------------------------------\n",
    "save_path = r\"D:\\è®ºæ–‡æ•°æ®\\2025.10 å‡ºå£é€‰æ‹©\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "file_name = os.path.join(save_path, \"ensemble_causal_results.csv\")\n",
    "\n",
    "df_result.to_csv(file_name, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\nğŸ“ ç»“æœå·²ä¿å­˜è‡³ï¼š{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a40c13-5e64-4d79-86b5-93b569a70bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c331e-a967-42a0-907d-bcaf3414d894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a635695-0848-42c6-b822-0d63704e58be",
   "metadata": {},
   "source": [
    "# 3.MSTAN-BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2cc6e30-4b36-45ed-9343-416c1676dc80",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_ne' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# =======================\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# å‡è®¾ df å·²ç»è¯»å…¥ï¼Œç›®æ ‡åˆ— 'NE'\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# =======================\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# å°†ç‰¹å¾åˆ—è½¬æ¢ä¸ºç±»åˆ«ç±»å‹\u001b[39;00m\n\u001b[0;32m      6\u001b[0m target_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNE\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 7\u001b[0m feature_cols \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf_ne\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;241m!=\u001b[39m target_col]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m feature_cols \u001b[38;5;241m+\u001b[39m [target_col]:\n\u001b[0;32m     10\u001b[0m     df_ne[col] \u001b[38;5;241m=\u001b[39m df_ne[col]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_ne' is not defined"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# å‡è®¾ df å·²ç»è¯»å…¥ï¼Œç›®æ ‡åˆ— 'NE'\n",
    "# =======================\n",
    "\n",
    "# å°†ç‰¹å¾åˆ—è½¬æ¢ä¸ºç±»åˆ«ç±»å‹\n",
    "target_col = 'NE'\n",
    "feature_cols = [col for col in df_ne.columns if col != target_col]\n",
    "\n",
    "for col in feature_cols + [target_col]:\n",
    "    df_ne[col] = df_ne[col].astype('category')\n",
    "\n",
    "X = df_ne[feature_cols]\n",
    "Y = df_ne[target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a540174-fba6-42b6-ab56-50805bcb2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# è®¡ç®—æ¡ä»¶äº’ä¿¡æ¯å‡½æ•°\n",
    "# =======================\n",
    "def conditional_mutual_info(X_i, X_j, Y):\n",
    "    mi = 0\n",
    "    for y_val, prob_y in Y.value_counts(normalize=True).items():\n",
    "        idx = (Y == y_val)\n",
    "        xi_subset = X_i[idx]\n",
    "        xj_subset = X_j[idx]\n",
    "        joint_counts = pd.crosstab(xi_subset, xj_subset)\n",
    "        joint_prob = joint_counts / joint_counts.values.sum()\n",
    "        xi_prob = joint_prob.sum(axis=1)\n",
    "        xj_prob = joint_prob.sum(axis=0)\n",
    "        for xi_val in joint_prob.index:\n",
    "            for xj_val in joint_prob.columns:\n",
    "                p_ij = joint_prob.at[xi_val, xj_val]\n",
    "                if p_ij > 0:\n",
    "                    mi += prob_y * p_ij * np.log(p_ij / (xi_prob[xi_val]*xj_prob[xj_val]))\n",
    "    return mi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061bf2e8-9140-42e8-8d70-4a916a9001b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# æ„å»ºæ¡ä»¶äº’ä¿¡æ¯çŸ©é˜µ & åˆ—è¡¨ L\n",
    "# =======================\n",
    "pairs = list(combinations(feature_cols, 2))\n",
    "I_dict = {}\n",
    "for Xi, Xj in pairs:\n",
    "    I_dict[(Xi, Xj)] = conditional_mutual_info(X[Xi], X[Xj], Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc8dc51-68b9-4fab-b8dd-0eca65f45a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŒ‰äº’ä¿¡æ¯é™åºæ’åˆ—\n",
    "L = sorted(I_dict.keys(), key=lambda x: I_dict[x], reverse=True)\n",
    "\n",
    "# =======================\n",
    "# æ„å»º TAN (MWST)\n",
    "# =======================\n",
    "# 1. ç”¨NetworkXæ„å»ºå›¾\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(feature_cols)\n",
    "for (Xi, Xj), w in I_dict.items():\n",
    "    G.add_edge(Xi, Xj, weight=w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db42f4d2-ba33-45a5-b3a6-35732360ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. æœ€å¤§åŠ æƒç”Ÿæˆæ ‘\n",
    "MWST = nx.maximum_spanning_tree(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4de604-2e7f-4106-a3b0-b7ae98f2e537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. è½¬ä¸ºæœ‰å‘å›¾ï¼Œé€‰æ‹©ä»»æ„æ ¹èŠ‚ç‚¹ï¼ˆè¿™é‡Œé€‰ç¬¬ä¸€ä¸ªç‰¹å¾åˆ—ï¼‰\n",
    "root = feature_cols[0]\n",
    "TAN_directed = nx.bfs_tree(MWST, root)\n",
    "T_r = {child: None for child in feature_cols}\n",
    "for parent, child in TAN_directed.edges():\n",
    "    T_r[child] = parent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8577236-7af0-437e-8a74-86201c4562ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# æ„å»º STAN\n",
    "# =======================\n",
    "def learn_STAN(X, Y, T_r, L, k=2):\n",
    "    S_r = T_r.copy()\n",
    "    G_dir = nx.DiGraph()\n",
    "    for child, parent in S_r.items():\n",
    "        if parent is not None:\n",
    "            G_dir.add_edge(parent, child)\n",
    "        else:\n",
    "            G_dir.add_node(child)\n",
    "    parent_count = {node: 0 for node in X.columns}\n",
    "    for child, parent in S_r.items():\n",
    "        if parent is not None:\n",
    "            parent_count[child] += 1\n",
    "    for Xi, Xj in L:\n",
    "        if G_dir.has_edge(Xi, Xj) or G_dir.has_edge(Xj, Xi):\n",
    "            continue\n",
    "        AH_i_j = conditional_mutual_info(X[Xi], X[Xj], Y)\n",
    "        AH_j_i = conditional_mutual_info(X[Xj], X[Xi], Y)\n",
    "        parent, child = (Xi, Xj) if AH_i_j > AH_j_i else (Xj, Xi)\n",
    "        if parent_count[child] < k:\n",
    "            G_dir.add_edge(parent, child)\n",
    "            if nx.is_directed_acyclic_graph(G_dir):\n",
    "                S_r[child] = parent\n",
    "                parent_count[child] += 1\n",
    "            else:\n",
    "                G_dir.remove_edge(parent, child)\n",
    "    return S_r\n",
    "\n",
    "S_r = learn_STAN(X, Y, T_r, L, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9910b41f-c57c-437e-9fa3-ad1204a34804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# è¾“å‡ºç»“æœ\n",
    "# =======================\n",
    "print(\"TANç»“æ„ (T_r):\")\n",
    "print(T_r)\n",
    "print(\"\\nSTANç»“æ„ (S_r):\")\n",
    "print(S_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e26c9-f40d-401d-a7f6-36dba3cc3226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "def plot_stan_structure(S_r, title=\"STAN Structure\"):\n",
    "    \"\"\"\n",
    "    S_r: dict {child: parent}\n",
    "    title: å›¾æ ‡é¢˜\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # æ·»åŠ èŠ‚ç‚¹å’Œè¾¹\n",
    "    for child, parent in S_r.items():\n",
    "        G.add_node(child)\n",
    "        if parent is not None:\n",
    "            G.add_edge(parent, child)\n",
    "    \n",
    "    # ä½ç½®å¸ƒå±€\n",
    "    pos = nx.spring_layout(G, seed=42)  # å¼¹ç°§å¸ƒå±€\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # ç»˜åˆ¶èŠ‚ç‚¹\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=1500, node_color='lightblue')\n",
    "    # ç»˜åˆ¶è¾¹\n",
    "    nx.draw_networkx_edges(G, pos, arrowstyle='-|>', arrowsize=20, edge_color='gray')\n",
    "    # ç»˜åˆ¶æ ‡ç­¾\n",
    "    nx.draw_networkx_labels(G, pos, font_size=12, font_weight='bold')\n",
    "    \n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# ===== ç»˜åˆ¶ STAN ç»“æ„ =====\n",
    "plot_stan_structure(S_r, title=\"STAN Structure for NE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d9accc-633f-4ccb-8ca6-613ce60e7aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6840f8-704c-4dee-82f1-827b50940859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a48e65-a50c-4179-b063-633ea3a3f5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5c62c-9249-42f8-bebc-ce51c48a3c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452d9269-1ae7-4e45-8481-7c9108d4a0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54851316-047c-43f2-957e-79482e4e0a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb53828-20af-4376-a3d2-156a93608b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72588be-c185-4561-a09d-e703c0f5dd37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
